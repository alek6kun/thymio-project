{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 01:17:00.928 python[43148:1202361] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1016.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1271.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1254.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det P 4.442978078651077e-07\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Argument 'radius' is required to be an integer\n>  - Argument 'radius' is required to be an integer\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/sergeelasmar/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/main.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m speed_left \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mv\u001b[39m.\u001b[39mmotor\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39mspeed\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m speed_right \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mv\u001b[39m.\u001b[39mmotor\u001b[39m.\u001b[39mright\u001b[39m.\u001b[39mspeed\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m rob_pos \u001b[39m=\u001b[39m filtering\u001b[39m.\u001b[39mrun_filter(speed_right, speed_left, rob_pos[\u001b[39m2\u001b[39m], vis)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m#rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Checking if we arrived at the next node\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m arrived_node \u001b[39m=\u001b[39m motion_functions\u001b[39m.\u001b[39mclose_coordinates(rob_pos[\u001b[39m0\u001b[39m], rob_pos[\u001b[39m1\u001b[39m], path[target_node][\u001b[39m0\u001b[39m], path[target_node][\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/filtering.py:59\u001b[0m, in \u001b[0;36mrun_filter\u001b[0;34m(speed_right, speed_left, prev_angle, vis)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDet P\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mdet(f\u001b[39m.\u001b[39mP))\n\u001b[1;32m     58\u001b[0m estimate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([f\u001b[39m.\u001b[39mx[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m camera_scale, f\u001b[39m.\u001b[39mx[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m camera_scale, f\u001b[39m.\u001b[39mx[\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m]])\n\u001b[0;32m---> 59\u001b[0m cv2\u001b[39m.\u001b[39;49mcircle(vis\u001b[39m.\u001b[39;49mcopy,(\u001b[39mint\u001b[39;49m(estimate[\u001b[39m0\u001b[39;49m]), \u001b[39mint\u001b[39;49m(estimate[\u001b[39m1\u001b[39;49m])),np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mdet(f\u001b[39m.\u001b[39;49mP),(\u001b[39m255\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m),\u001b[39m3\u001b[39;49m)\n\u001b[1;32m     60\u001b[0m cv2\u001b[39m.\u001b[39mline(vis\u001b[39m.\u001b[39mcopy, (\u001b[39mint\u001b[39m(estimate[\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(estimate[\u001b[39m1\u001b[39m])), (\u001b[39mint\u001b[39m(estimate[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mcos(estimate[\u001b[39m2\u001b[39m])), \u001b[39mint\u001b[39m(estimate[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m100\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msin(estimate[\u001b[39m2\u001b[39m]))), (\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), \u001b[39m3\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m estimate\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Argument 'radius' is required to be an integer\n>  - Argument 'radius' is required to be an integer\n"
     ]
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import vision.ComputerVision\n",
    "import time\n",
    "import cv2\n",
    "import motion_functions\n",
    "import filtering\n",
    "import numpy as np\n",
    "\n",
    "dt = 0.05 # [s] Time delta between minimum image acquisition\n",
    "\n",
    "vis = vision.ComputerVision.Vision()\n",
    "\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "last_image_time = time.time()\n",
    "dt = 0.05\n",
    "path = []\n",
    "\n",
    "state = 0 # FSM state\n",
    "goal_reached = False\n",
    "kidnapped = 0\n",
    "obstacle_detected = 0\n",
    "\n",
    "while True:\n",
    "    while state == 0: # Goal, robot and path aquisition state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        rotation_done = 1 # Boolean to check if the robot is currently rotating (1 means no)\n",
    "        target_node = 0 # Initial node\n",
    "        \n",
    "        path = vis.shortest_path\n",
    "        # Check if a path was found\n",
    "        if len(path)>=1:\n",
    "            state = 1\n",
    "            rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "            filtering.f.x = np.array([vis.robot.x/vis.scale, vis.robot.y/vis.scale, -vis.robot.angle])\n",
    "\n",
    "    while state == 1: # Drive towards goal state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        \n",
    "        # Get proximity sensors' values\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        # Checking for unforseen obstacle\n",
    "        if obstacle_detected:\n",
    "            await motion_functions.stop(node)\n",
    "            state = 4\n",
    "            break\n",
    "        \n",
    "        # Checking for kidnapping\n",
    "        if kidnapped:\n",
    "            state = 3 # Kidnapped state\n",
    "            vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "            await motion_functions.stop(node)\n",
    "            break\n",
    "        \n",
    "        # Setting up and running the Kalman Filter\n",
    "        speed_left = node.v.motor.left.speed\n",
    "        speed_right = node.v.motor.right.speed\n",
    "        rob_pos = filtering.run_filter(speed_right, speed_left, rob_pos[2], vis)\n",
    "        #rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "        \n",
    "        # Checking if we arrived at the next node\n",
    "        arrived_node = motion_functions.close_coordinates(rob_pos[0], rob_pos[1], path[target_node][0], path[target_node][1])\n",
    "        if (arrived_node):\n",
    "            if (target_node) < len(path)-1:\n",
    "                target_node += 1\n",
    "            else:\n",
    "                await motion_functions.stop(node)\n",
    "                goal_reached = True\n",
    "                break \n",
    "        \n",
    "        # Rotating and driving towards the next node\n",
    "        if rotation_done:\n",
    "            angle = motion_functions.compute_movement([rob_pos[0], rob_pos[1]], [path[target_node][0], path[target_node][1]])\n",
    "            if abs(angle - rob_pos[2]) > 0.2:\n",
    "                rotation_done = 0\n",
    "                await motion_functions.rotate(angle-rob_pos[2], node)\n",
    "            \n",
    "        if  angle + 0.2 > rob_pos[2] and angle - 0.2 < rob_pos[2]:\n",
    "            rotation_done = 1\n",
    "            await motion_functions.drive(node)\n",
    "        \n",
    "            \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    while state == 3: # State in case of kidnapping\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        # Checking if the robot is still kidnapped\n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        if not kidnapped:\n",
    "            state = 0\n",
    "        \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    while state == 4: # Local avoidance state\n",
    "        vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "        \n",
    "        while obstacle_detected:\n",
    "            while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "                continue\n",
    "            vis.show()\n",
    "            vis.update()\n",
    "            \n",
    "            # Checking if we still detect obstacles\n",
    "            await client.sleep(0.01)\n",
    "            await node.wait_for_variables()\n",
    "            kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "            # Drive backwards as long as an obstacle is detected\n",
    "            await motion_functions.drive_back(node)\n",
    "            \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Stop and return to state 0 to compute a new path\n",
    "        await motion_functions.stop(node)\n",
    "        state = 0\n",
    "    \n",
    "    if goal_reached:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del vis\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await motion_functions.stop(node)\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicsofmob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
