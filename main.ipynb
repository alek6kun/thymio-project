{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 23:10:20.774 python[37347:1097623] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1326.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1478.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1602.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1298.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1490.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1793.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1709.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1760.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1720.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1666.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1779.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1680.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1669.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1744.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1531.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1738.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1769.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 593.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 845.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 885.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 520.00it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 543.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 541.31it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 546.92it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 514.54it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 673.68it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 561.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 488.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 620.18it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 606.99it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 488.31it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 556.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 450.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 527.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 541.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 558.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 558.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 553.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 820.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 568.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 537.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 441.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 537.21it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 522.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 520.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 540.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 549.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 537.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 543.48it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 532.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 517.59it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 528.95it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 527.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 535.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 850.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 535.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 531.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 516.79it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 549.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 548.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 564.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 538.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 536.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 533.93it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 534.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 484.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 462.77it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 532.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 538.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 528.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 527.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 518.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 457.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 536.60it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 485.34it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 549.50it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 543.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 526.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 540.26it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 471.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 529.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 529.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 521.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 769.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 474.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 461.67it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 528.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 630.53it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 514.58it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Point(1714.00, 852.00)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/sergeelasmar/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/main.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m vis\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m vis\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mawait\u001b[39;00m node\u001b[39m.\u001b[39mwait_for_variables()\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/vision/ComputerVision.py:97\u001b[0m, in \u001b[0;36mVision.update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoal \u001b[39m=\u001b[39m goal\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfound_robot \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfound_goal \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfound_graph:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortest_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_shortest_path()\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/vision/ComputerVision.py:105\u001b[0m, in \u001b[0;36mVision.find_shortest_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_shortest_path\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     shortest \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mshortest_path(vg\u001b[39m.\u001b[39;49mPoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrobot\u001b[39m.\u001b[39;49mx,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrobot\u001b[39m.\u001b[39;49my),\n\u001b[1;32m    106\u001b[0m                                         vg\u001b[39m.\u001b[39;49mPoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoal\u001b[39m.\u001b[39;49mx,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoal\u001b[39m.\u001b[39;49my))\n\u001b[1;32m    108\u001b[0m     shortest_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(point\u001b[39m.\u001b[39mx, point\u001b[39m.\u001b[39my) \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m shortest], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m    109\u001b[0m     \u001b[39m# Draw shortest path\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/basicsofmob/lib/python3.9/site-packages/pyvisgraph/vis_graph.py:130\u001b[0m, in \u001b[0;36mVisGraph.shortest_path\u001b[0;34m(self, origin, destination)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m visible_vertices(destination, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph, origin\u001b[39m=\u001b[39morgn):\n\u001b[1;32m    129\u001b[0m         add_to_visg\u001b[39m.\u001b[39madd_edge(Edge(destination, v))\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m shortest_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisgraph, origin, destination, add_to_visg)\n",
      "File \u001b[0;32m~/anaconda3/envs/basicsofmob/lib/python3.9/site-packages/pyvisgraph/shortest_path.py:70\u001b[0m, in \u001b[0;36mshortest_path\u001b[0;34m(graph, origin, destination, add_to_visgraph)\u001b[0m\n\u001b[1;32m     68\u001b[0m     path\u001b[39m.\u001b[39mappend(destination)\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m destination \u001b[39m==\u001b[39m origin: \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     destination \u001b[39m=\u001b[39m P[destination]\n\u001b[1;32m     71\u001b[0m path\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "\u001b[0;31mKeyError\u001b[0m: Point(1714.00, 852.00)"
     ]
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import vision.ComputerVision\n",
    "import time\n",
    "import cv2\n",
    "import motion_functions\n",
    "import filtering\n",
    "\n",
    "R = 0.021 # [m] The radius of the Thymio's wheels\n",
    "d = 0.095 # [m] The wheelbase of the Thymio\n",
    "dt = 0.05 # [s] Time delta between steps\n",
    "\n",
    "vis = vision.ComputerVision.Vision()\n",
    "\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "last_image_time = time.time()\n",
    "dt = 0.05\n",
    "path = []\n",
    "\n",
    "state = 0 # FSM state\n",
    "goal_reached = False\n",
    "kidnapped = 0\n",
    "obstacle_detected = 0\n",
    "\n",
    "while True:\n",
    "    while state == 0: # Goal, robot and path aquisition state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        rotation_done = 1 # Boolean to check if the robot is currently rotating (1 means no)\n",
    "        target_node = 0 # Initial node\n",
    "        \n",
    "        path = vis.shortest_path\n",
    "        # Check if a path was found\n",
    "        if len(path)>=1:\n",
    "            state = 1\n",
    "            rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "\n",
    "    while state == 1: # Drive towards goal state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        \n",
    "        # Get proximity sensors' values\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        # Checking for unforseen obstacle\n",
    "        if obstacle_detected:\n",
    "            await motion_functions.stop(node)\n",
    "            state = 4\n",
    "            break\n",
    "        \n",
    "        # Checking for kidnapping\n",
    "        if kidnapped:\n",
    "            state = 3 # Kidnapped state\n",
    "            vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "            await motion_functions.stop(node)\n",
    "            break\n",
    "        \n",
    "        # Setting up and running the Kalman Filter\n",
    "        speed_left = node.v.motor.left.speed\n",
    "        speed_right = node.v.motor.right.speed\n",
    "        prev_angle = rob_pos[2]\n",
    "        rob_pos_2 = filtering.run_filter(speed_right, speed_left, prev_angle, vis,R,d,time.time()-last_image_time)\n",
    "        rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "        \n",
    "        # Checking if we arrived at the next node\n",
    "        arrived_node = motion_functions.close_coordinates(rob_pos[0], rob_pos[1], path[target_node][0], path[target_node][1])\n",
    "        if (arrived_node):\n",
    "            if (target_node) < len(path)-1:\n",
    "                target_node += 1\n",
    "            else:\n",
    "                await motion_functions.stop(node)\n",
    "                goal_reached = True\n",
    "                break \n",
    "        \n",
    "        # Rotating and driving towards the next node\n",
    "        if rotation_done:\n",
    "            angle = motion_functions.compute_movement([rob_pos[0], rob_pos[1]], [path[target_node][0], path[target_node][1]])\n",
    "            if abs(angle - rob_pos[2]) > 0.2:\n",
    "                rotation_done = 0\n",
    "                await motion_functions.rotate(angle-rob_pos[2], node)\n",
    "            \n",
    "        if  angle + 0.2 > rob_pos[2] and angle - 0.2 < rob_pos[2]:\n",
    "            rotation_done = 1\n",
    "            await motion_functions.drive(node)\n",
    "        \n",
    "            \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    while state == 3: # State in case of kidnapping\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        # Checking if the robot is still kidnapped\n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        if not kidnapped:\n",
    "            state = 0\n",
    "        \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    while state == 4: # Local avoidance state\n",
    "        vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "        \n",
    "        while obstacle_detected:\n",
    "            while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "                continue\n",
    "            vis.show()\n",
    "            vis.update()\n",
    "            \n",
    "            # Checking if we still detect obstacles\n",
    "            await client.sleep(0.01)\n",
    "            await node.wait_for_variables()\n",
    "            kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "            # Drive backwards as long as an obstacle is detected\n",
    "            await motion_functions.drive_back(node)\n",
    "            \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Stop and return to state 0 to compute a new path\n",
    "        await motion_functions.stop(node)\n",
    "        state = 0\n",
    "    \n",
    "    if goal_reached:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del vis\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await motion_functions.stop(node)\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicsofmob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
