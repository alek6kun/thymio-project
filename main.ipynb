{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 19:11:59.564 python[8132:203059] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading frame.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/sergeelasmar/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/main.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dt \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m \u001b[39m# [s] Time delta between minimum image acquisition\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m vis \u001b[39m=\u001b[39m vision\u001b[39m.\u001b[39;49mComputerVision\u001b[39m.\u001b[39;49mVision()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m client \u001b[39m=\u001b[39m ClientAsync()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sergeelasmar/Desktop/EPFL/MA1/Basics%20of%20mobile%20robotics/Project/thymio-project/main.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39mwait_for_node()\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA1/Basics of mobile robotics/Project/thymio-project/vision/ComputerVision.py:64\u001b[0m, in \u001b[0;36mVision.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid:\n\u001b[1;32m     63\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError reading frame.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfound_robot, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrobot, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_robot()\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfound_graph, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvertices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_graph()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import vision.ComputerVision\n",
    "import time\n",
    "import cv2\n",
    "import motion_functions\n",
    "import filtering\n",
    "import numpy as np\n",
    "\n",
    "dt = 0.05 # [s] Time delta between minimum image acquisition\n",
    "\n",
    "vis = vision.ComputerVision.Vision()\n",
    "\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "last_image_time = time.time()\n",
    "dt = 0.05\n",
    "path = []\n",
    "\n",
    "angle_tol = 0.2 # Tolerance on angle\n",
    "state = 0 # FSM initial state\n",
    "goal_reached = False\n",
    "kidnapped = 0 # Boolean checking if the robot is currently kidnapped\n",
    "obstacle_detected = 0 # Boolean checking if an obstacle is detected by the frontal proximity sensors\n",
    "\n",
    "while True:\n",
    "    while state == 0: # Goal, robot and path aquisition state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update(path)\n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        rotation_done = 1 # Boolean to check if the robot is currently rotating (1 means no)\n",
    "        target_node = 0 # Initial node\n",
    "        \n",
    "        path = vis.shortest_path\n",
    "        # Check if a path was found\n",
    "        if len(path)>=1:\n",
    "            state = 1\n",
    "            rob_pos = [vis.robot.x, vis.robot.y, vis.robot.angle]\n",
    "            filtering.f.x = np.array([vis.robot.x/vis.scale, vis.robot.y/vis.scale, vis.robot.angle])\n",
    "\n",
    "    while state == 1: # Drive towards goal state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update(path)\n",
    "        \n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        \n",
    "        # Get proximity sensors' values\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        # Checking for unforseen obstacle\n",
    "        if obstacle_detected:\n",
    "            await motion_functions.stop(node)\n",
    "            state = 2\n",
    "            break\n",
    "        \n",
    "        # Checking for kidnapping\n",
    "        if kidnapped:\n",
    "            state = 3 # Kidnapped state\n",
    "            vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "            await motion_functions.stop(node)\n",
    "            break\n",
    "        \n",
    "        # Setting up and running the Kalman Filter\n",
    "        speed_left = node.v.motor.left.speed\n",
    "        speed_right = node.v.motor.right.speed\n",
    "        rob_pos = filtering.run_filter(speed_right, speed_left, rob_pos[2], vis)\n",
    "        \n",
    "        # Checking if we arrived at the next node\n",
    "        arrived_node = motion_functions.close_coordinates(rob_pos[0], rob_pos[1], path[target_node][0], path[target_node][1])\n",
    "        if (arrived_node):\n",
    "            if (target_node) < len(path)-1:\n",
    "                target_node += 1\n",
    "            else:\n",
    "                await motion_functions.stop(node)\n",
    "                goal_reached = True\n",
    "                break \n",
    "        \n",
    "        # Rotating and driving towards the next node\n",
    "        if rotation_done:\n",
    "            angle = motion_functions.compute_movement([rob_pos[0], rob_pos[1]], [path[target_node][0], path[target_node][1]])\n",
    "            if abs(angle - rob_pos[2]) > angle_tol: # If the difference in angle is smaller than angle_tol we stop turning\n",
    "                rotation_done = 0\n",
    "                await motion_functions.rotate(angle-rob_pos[2], node)\n",
    "            \n",
    "        if  angle + 0.2 > rob_pos[2] and angle - 0.2 < rob_pos[2]:\n",
    "            rotation_done = 1\n",
    "            await motion_functions.drive(node)\n",
    "        \n",
    "            \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    while state == 3: # State in case of kidnapping\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update(path)\n",
    "        \n",
    "        # Checking if the robot is still kidnapped\n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        if not kidnapped:\n",
    "            await client.sleep(0.75) # Wait a bit to make sure our arm is not in the camera shot anymore as it creates noise.\n",
    "            state = 0\n",
    "        \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    while state == 2: # Local avoidance state\n",
    "        vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "        \n",
    "        while obstacle_detected:\n",
    "            while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "                continue\n",
    "            vis.show()\n",
    "            vis.update(path)\n",
    "            \n",
    "            # Checking if we still detect obstacles\n",
    "            await client.sleep(0.01)\n",
    "            await node.wait_for_variables()\n",
    "            kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "            # Drive backwards as long as an obstacle is detected\n",
    "            await motion_functions.drive_back(node)\n",
    "            \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Stop and return to state 0 to compute a new path\n",
    "        await motion_functions.stop(node)\n",
    "        await client.sleep(0.5)  # Wait a bit to make sure our arm is not in the camera shot anymore as it creates noise.\n",
    "        state = 0\n",
    "    \n",
    "    if goal_reached:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del vis\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicsofmob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
