{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import vision.ComputerVision\n",
    "import time\n",
    "import cv2\n",
    "import motion_functions\n",
    "import filtering\n",
    "import numpy as np\n",
    "\n",
    "dt = 0.05 # [s] Time delta between minimum image acquisition\n",
    "\n",
    "vis = vision.ComputerVision.Vision()\n",
    "\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "last_image_time = time.time()\n",
    "dt = 0.05\n",
    "path = []\n",
    "\n",
    "state = 0 # FSM initial state\n",
    "goal_reached = False\n",
    "kidnapped = 0 # Boolean checking if the robot is currently kidnapped\n",
    "obstacle_detected = 0 # Boolean checking if an obstacle is detected by the frontal proximity sensors\n",
    "\n",
    "while True:\n",
    "    while state == 0: # Goal, robot and path aquisition state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        rotation_done = 1 # Boolean to check if the robot is currently rotating (1 means no)\n",
    "        target_node = 0 # Initial node\n",
    "        \n",
    "        path = vis.shortest_path\n",
    "        # Check if a path was found\n",
    "        if len(path)>=1:\n",
    "            state = 1\n",
    "            rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "            filtering.f.x = np.array([vis.robot.x/vis.scale, vis.robot.y/vis.scale, -vis.robot.angle])\n",
    "\n",
    "    while state == 1: # Drive towards goal state\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        \n",
    "        # Get proximity sensors' values\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        # Checking for unforseen obstacle\n",
    "        if obstacle_detected:\n",
    "            await motion_functions.stop(node)\n",
    "            state = 4\n",
    "            break\n",
    "        \n",
    "        # Checking for kidnapping\n",
    "        if kidnapped:\n",
    "            state = 3 # Kidnapped state\n",
    "            vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "            await motion_functions.stop(node)\n",
    "            break\n",
    "        \n",
    "        # Setting up and running the Kalman Filter\n",
    "        speed_left = node.v.motor.left.speed\n",
    "        speed_right = node.v.motor.right.speed\n",
    "        rob_pos = filtering.run_filter(speed_right, speed_left, rob_pos[2], vis)\n",
    "        #rob_pos = [vis.robot.x, vis.robot.y, -vis.robot.angle]\n",
    "        \n",
    "        # Checking if we arrived at the next node\n",
    "        arrived_node = motion_functions.close_coordinates(rob_pos[0], rob_pos[1], path[target_node][0], path[target_node][1])\n",
    "        if (arrived_node):\n",
    "            if (target_node) < len(path)-1:\n",
    "                target_node += 1\n",
    "            else:\n",
    "                await motion_functions.stop(node)\n",
    "                goal_reached = True\n",
    "                break \n",
    "        \n",
    "        # Rotating and driving towards the next node\n",
    "        if rotation_done:\n",
    "            angle = motion_functions.compute_movement([rob_pos[0], rob_pos[1]], [path[target_node][0], path[target_node][1]])\n",
    "            if abs(angle - rob_pos[2]) > 0.2:\n",
    "                rotation_done = 0\n",
    "                await motion_functions.rotate(angle-rob_pos[2], node)\n",
    "            \n",
    "        if  angle + 0.2 > rob_pos[2] and angle - 0.2 < rob_pos[2]:\n",
    "            rotation_done = 1\n",
    "            await motion_functions.drive(node)\n",
    "        \n",
    "            \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    while state == 3: # State in case of kidnapping\n",
    "        while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "            continue\n",
    "        vis.show()\n",
    "        vis.update()\n",
    "        \n",
    "        # Checking if the robot is still kidnapped\n",
    "        await client.sleep(0.01)\n",
    "        await node.wait_for_variables()\n",
    "        kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "        \n",
    "        if not kidnapped:\n",
    "            await client.sleep(0.75) # Wait a bit to make sure our arm is not in the camera shot anymore as it creates noise.\n",
    "            state = 0\n",
    "        \n",
    "        last_image_time = time.time()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    while state == 4: # Local avoidance state\n",
    "        vis.shortest_path = [] # Deleting the previous path to make sure a new one is computed\n",
    "        \n",
    "        while obstacle_detected:\n",
    "            while time.time()-last_image_time < dt: # Aquire a new image every dt seconds\n",
    "                continue\n",
    "            vis.show()\n",
    "            vis.update()\n",
    "            \n",
    "            # Checking if we still detect obstacles\n",
    "            await client.sleep(0.01)\n",
    "            await node.wait_for_variables()\n",
    "            kidnapped, obstacle_detected = motion_functions.get_sensors(node)\n",
    "            # Drive backwards as long as an obstacle is detected\n",
    "            await motion_functions.drive_back(node)\n",
    "            \n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Stop and return to state 0 to compute a new path\n",
    "        await motion_functions.stop(node)\n",
    "        await client.sleep(0.5)  # Wait a bit to make sure our arm is not in the camera shot anymore as it creates noise.\n",
    "        state = 0\n",
    "    \n",
    "    if goal_reached:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del vis\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await motion_functions.stop(node)\n",
    "await node.unlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicsofmob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
